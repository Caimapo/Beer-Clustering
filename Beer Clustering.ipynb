{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "## Tarea 1 - Beer Clustering\n",
    "### Reconocimiento de patrones en Minería de Datos\n",
    "\n",
    "Para esta tarea se realizara la implementación de los algoritmos de clustering: *K-means, Minibatch K-means, HAC Complete, DBSCAN* para el análisis de las reseñas obtenidos de la página beeradvocate la cual consta de un poco más de un millón y medio de datos como el dataset de prueba de los algoritmos, en los cuales se estudiara los valores de entrada de cada uno para obtener los clusters más adecuados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-Means**\n",
    "K-Means es un método de clustering que tiene como objetivo particionar n mediciones de un conjunto en k grupos en la que cada observación pertenece al grupo cuyo centroide es más cercano dentro de la distribución de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "np.random.seed(0)\n",
    "centers = [[1,1],[-1,-1]]\n",
    "X, labels_true = make_blobs(n_samples=10000, centers=centers, cluster_std = 0.1)\n",
    "from sklearn.cluster import KMeans\n",
    "k_means = KMeans(init=\"random\", n_clusters=2, n_init=10)\n",
    "k_means.fit(X)\n",
    "k_means_labels = k_means.labels_\n",
    "k_means_cluster_centers = k_means.cluster_centers_\n",
    "fig = plt.figure(figsize=(3,3))\n",
    "colors = ['#4EACC5','#FF9C34','#4E9A06']\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.set_title('KMeans')\n",
    "for k, col in zip(range(3), colors):\n",
    "\tmy_members = k_means_labels == k\n",
    "\tax.plot(X[my_members, 0], X[my_members, 1], 'w', markerfacecolor=col, marker='.')\n",
    "\t\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Minibatch K-MEANS**\n",
    "Es una variación del algoritmo de K-means que se usa pequeños lotes \"mini-batches\" de datos para correr k-means cuando la colección de datos es muy grande para que quepa en memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HAC Complete**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits(n_class=10)\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "n_samples, n_features = X.shape\n",
    "from sklearn import manifold\n",
    "X_red = manifold.SpectralEmbedding(n_components=2).fit_transform(X)\n",
    "from sklearn.cluster import AgglomerativeClustering as hac\n",
    "clustering = hac(linkage=\"average\", n_clusters=10, affinity=\"euclidean\")\n",
    "clustering.fit(X)\n",
    "x_min, x_max = numpy.min(X_red, axis=0), numpy.max(X_red, axis=0)\n",
    "X_red = (X_red - x_min)/(x_max - x_min)\n",
    "for i in range(X_red.shape[0]):\n",
    "\tplt.text(X_red[i,0], X_red[i,1], str(y[i]),\n",
    "\tcolor=plt.cm.spectral(clustering.labels_[i]/10.),\n",
    "\tfontdict={'weight': 'bold', 'size': 8})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DBSCAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TabError",
     "evalue": "inconsistent use of tabs and spaces in indentation (<ipython-input-1-29ce6d8f4786>, line 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-29ce6d8f4786>\"\u001b[0;36m, line \u001b[0;32m25\u001b[0m\n\u001b[0;31m    plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=col, markeredgecolor='k', markersize=6)\u001b[0m\n\u001b[0m                                                                                             ^\u001b[0m\n\u001b[0;31mTabError\u001b[0m\u001b[0;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"
     ]
    }
   ],
   "source": [
    "import numpy, scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import datasets\n",
    "\n",
    "noisy_moons = datasets.make_moons(n_samples=1000, noise=.05)\n",
    "X, y = noisy_moons\n",
    "X = StandardScaler().fit_transform(X)\n",
    "db = DBSCAN(eps=0.3, min_samples=10).fit(X)\n",
    "core_samples_mask = numpy.zeros_like(db.labels_, dtype = bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "unique_labels = set(labels)\n",
    "colors = plt.cm.Spectral(numpy.linspace(0, 1, len(unique_labels)))\n",
    "for k, col in zip(unique_labels, colors):\n",
    "\tif k == -1:\n",
    "\t\tcol = 'k'\n",
    "\n",
    "\tclass_member_mask = (labels == k)\n",
    "\n",
    "\txy = X[class_member_mask & core_samples_mask]\n",
    "\tplt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=col, markeredgecolor='k', markersize=10)\n",
    "\txy = X[class_member_mask & ~core_samples_mask]\n",
    "        plt.plot(xy[:, 0], xy[:, 1], 'o', markerfacecolor=col, markeredgecolor='k', markersize=6)\n",
    "\n",
    "plt.title(\"DBSCAN\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TODO/ Mostrar una visualización por cada algoritmo, Realizar ajustes a los parámentros para lograr un buen cluster..JUSTIFICAR PROCEDIMIENTO Y ELECCIÓN DE PARÁMETROS.\n",
    "\n",
    "Encontrar el atributo que mejor representa el cluster, nombre de cervecería ó tipo de cerveza?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
